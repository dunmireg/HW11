{"paragraphs":[{"text":"%md \n\n# Homework 11 # \n<p>Ron Cordell, Ted Dunmire, Filip Krunic</p><br>\n\n-----\n\n### Question 11.0 ###\n<p><i>What is the difference between broadcasting and caching data in Spark? Give an example (in the context of machine learning) of each mechanism (at a highlevel). Feel free to cut and paste code examples from the lectures to support your answer.</i></p><br>\n\n<p><i>Review the following <a href=https://www.dropbox.com/s/41q9lgyqhy8ed5g/EM-Kmeans.ipynb?dl=0>Spark-notebook-based implementation of KMeans</a> and use the broadcast pattern to make this implementation more efficient. Please describe your changes in English first, implement, comment your code and highlight your changes. </i></p><br>\n\n\n#### Solution: ####\n\n<p>A broadcasted object is dynamic in memory, whereas a cached object is not. For example, if one has an input dataset into a machine learning algorithm within Spark, the data would be statically cached as it does not change. Alternatively, a broadcasted variable may be centroid coordinates or error-trackers that are required to change after each iteration, but have to be held in each node's memory to be accessed. </p>","dateUpdated":"Apr 3, 2016 11:56:47 AM","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/markdown","editorHide":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1459686072407_603670571","id":"20160403-082112_2088506528","result":{"code":"SUCCESS","type":"HTML","msg":"<h1>Homework 11</h1>\n<p>Ron Cordell, Ted Dunmire, Filip Krunic</p><br>\n<hr />\n<h3>Question 11.0</h3>\n<p><i>What is the difference between broadcasting and caching data in Spark? Give an example (in the context of machine learning) of each mechanism (at a highlevel). Feel free to cut and paste code examples from the lectures to support your answer.</i></p><br>\n<p><i>Review the following <a href=https://www.dropbox.com/s/41q9lgyqhy8ed5g/EM-Kmeans.ipynb?dl=0>Spark-notebook-based implementation of KMeans</a> and use the broadcast pattern to make this implementation more efficient. Please describe your changes in English first, implement, comment your code and highlight your changes. </i></p><br>\n<h4>Solution:</h4>\n<p>A broadcasted object is dynamic in memory, whereas a cached object is not. For example, if one has an input dataset into a machine learning algorithm within Spark, the data would be statically cached as it does not change. Alternatively, a broadcasted variable may be centroid coordinates or error-trackers that are required to change after each iteration, but have to be held in each node's memory to be accessed. </p>\n"},"dateCreated":"Apr 3, 2016 8:21:12 AM","dateStarted":"Apr 3, 2016 11:56:39 AM","dateFinished":"Apr 3, 2016 11:56:39 AM","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:17","focus":true},{"config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorHide":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1459690243254_-2001904297","id":"20160403-093043_231970716","dateCreated":"Apr 3, 2016 9:30:43 AM","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:20","dateUpdated":"Apr 3, 2016 2:42:19 PM","dateFinished":"Apr 3, 2016 2:42:14 PM","dateStarted":"Apr 3, 2016 2:42:14 PM","result":{"code":"SUCCESS","type":"ANGULAR","msg":"<!DOCTYPE html>\n<html>\n<head>\n<title>MathJax Test Page</title>\n<script type=\"text/javascript\" async\n  src=\"https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=AM_CHTML\"></script>\n</head>\n<body>\n\n<hr>\n\n<h3> Question 11.1 </h3>\n\n<p><i>In the context of binary classification problems, does the linear SVM learning algorithm yield the same result as a L2 penalized logistic regession learning algorithm? In your reponse, please discuss the loss functions, and the learnt models, and separating surfaces between the two classes. </i></p><br>\n\n<p><i>In the context of binary classification problems, does the linear SVM learning algorithm yield the same result as a perceptron learning algorithm? </i></p><br>\n\n<p><i><b>Optional</b>: Generate an artifical binary classification dataset with 2 input features and plot the learnt separating surface for both a linear SVM and for  logistic regression. Comment on the learnt surfaces. Please feel free to do this in Python (no need to use Spark).</i></p><br>\n\n<h4> Solution: </h4> \n\n<p>A linear SVM will not necessarily yield the same result as an L2 penalized logistic regression. If the linear SVM has a hard-margin, it will necessarily fail on datasets that are not linearly separable, whereas an L2 penalized logistic regression will not. A soft-margin linear SVM has an L2 penalty like a L2 penalized logistic regression, but it differers in that the linear SVM uses hinge-loss to maximize the margin and the L2 penalized logistic regression uses the linear predictor \"p/1-p\" predicted from the logit function. </p><br>\n\n<p>A linear SVM will not necessarily yield the same result as a perceptron. A hard-margin linear SVM has a non-separability drawback, whereas a perceptron like the L2 penalized logistic regression does not. This means that the perceptron may converge to a model on a non-linearly separable dataset, whereas the hard-margin SVM will not. Although both the linear-SVM and perceptron will tend to zero-out non-predictive fields in the data, they do so using different loss functions- hinge loss and step loss, respectively. </p>\n\n<p style=\"text-align:center\">\n  `x = (-b +- sqrt(b^2-4ac))/(2a) .`\n</p>\n\n</body>\n</html>"},"text":"%angular\n\n<!DOCTYPE html>\n<html>\n<head>\n<title>MathJax Test Page</title>\n<script type=\"text/javascript\" async\n  src=\"https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=AM_CHTML\"></script>\n</head>\n<body>\n\n<hr>\n\n<h3> Question 11.1 </h3>\n\n<p><i>In the context of binary classification problems, does the linear SVM learning algorithm yield the same result as a L2 penalized logistic regession learning algorithm? In your reponse, please discuss the loss functions, and the learnt models, and separating surfaces between the two classes. </i></p><br>\n\n<p><i>In the context of binary classification problems, does the linear SVM learning algorithm yield the same result as a perceptron learning algorithm? </i></p><br>\n\n<p><i><b>Optional</b>: Generate an artifical binary classification dataset with 2 input features and plot the learnt separating surface for both a linear SVM and for  logistic regression. Comment on the learnt surfaces. Please feel free to do this in Python (no need to use Spark).</i></p><br>\n\n<h4> Solution: </h4> \n\n<p>A linear SVM will not necessarily yield the same result as an L2 penalized logistic regression. If the linear SVM has a hard-margin, it will necessarily fail on datasets that are not linearly separable, whereas an L2 penalized logistic regression will not. A soft-margin linear SVM has an L2 penalty like a L2 penalized logistic regression, but it differers in that the linear SVM uses hinge-loss to maximize the margin and the L2 penalized logistic regression uses the linear predictor \"p/1-p\" predicted from the logit function. </p><br>\n\n<p>A linear SVM will not necessarily yield the same result as a perceptron. A hard-margin linear SVM has a non-separability drawback, whereas a perceptron like the L2 penalized logistic regression does not. This means that the perceptron may converge to a model on a non-linearly separable dataset, whereas the hard-margin SVM will not. Although both the linear-SVM and perceptron will tend to zero-out non-predictive fields in the data, they do so using different loss functions- hinge loss and step loss, respectively. </p>\n\n<p style=\"text-align:center\">\n  `x = (-b +- sqrt(b^2-4ac))/(2a) .`\n</p>\n\n</body>\n</html>","focus":true},{"config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/markdown","editorHide":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1459698064712_1677005484","id":"20160403-114104_1986404203","dateCreated":"Apr 3, 2016 11:41:04 AM","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:147","dateUpdated":"Apr 3, 2016 1:39:17 PM","dateFinished":"Apr 3, 2016 1:39:11 PM","dateStarted":"Apr 3, 2016 1:39:11 PM","result":{"code":"SUCCESS","type":"HTML","msg":"<hr />\n<h3>Question 11.2</h3>\n<p><i>In the context of logistic regression describe and define three flavors of penalized loss functions.  Are these all supported in Spark MLLib (include online references to support your answers)? </i></p><br>\n<p><i>Describe probabilitic interpretations of the L1 and L2 priors for penalized logistic regression (HINT: see synchronous slides for week 11 for details).</i></p><br>\n<h4>Solution:</h4>\n<p><p> Three commonly used loss-functions for logistic regression are <b>hinge loss</b>, <b>logistic loss</b>, and <b>cross-entropy</b> loss. Only the first two are available in Spark MLLib. The probabilistic interpretation for L1 priors is that they prefer to reduce the number of variables used to prevent overfitting over reducing the overall size of the variable coefficients. This is contrasted with L2 priors that prefer to reduce coefficient magnitude rather than the number of variables used. Lasso regressions find a balance between L1 and L2 regularization by doing both with a weight-factor that ties these two penalties together. <p><br></p>\n<p>References: </p><br>\n<p><li><a href=http: //mathjax.readthedocs.org/en/latest/start.html>Spark MLLib</a></li>\n<br  /><li><a href=http: //www.ics.uci.edu/~dramanan/teaching/ics273a_winter08/lectures/lecture14.pdf>Loss functions</a></li>\n<br  /><br></p>\n"},"text":"%md \n\n-----\n\n### Question 11.2 ###\n\n<p><i>In the context of logistic regression describe and define three flavors of penalized loss functions.  Are these all supported in Spark MLLib (include online references to support your answers)? </i></p><br>\n\n<p><i>Describe probabilitic interpretations of the L1 and L2 priors for penalized logistic regression (HINT: see synchronous slides for week 11 for details).</i></p><br>\n\n#### Solution: ####\n\n<p> Three commonly used loss-functions for logistic regression are <b>hinge loss</b>, <b>logistic loss</b>, and <b>cross-entropy</b> loss. Only the first two are available in Spark MLLib. The probabilistic interpretation for L1 priors is that they prefer to reduce the number of variables used to prevent overfitting over reducing the overall size of the variable coefficients. This is contrasted with L2 priors that prefer to reduce coefficient magnitude rather than the number of variables used. Lasso regressions find a balance between L1 and L2 regularization by doing both with a weight-factor that ties these two penalties together. <p><br>\n\n<p>References: </p><br>\n<li><a href=http://mathjax.readthedocs.org/en/latest/start.html>Spark MLLib</a></li>\n<li><a href=http://www.ics.uci.edu/~dramanan/teaching/ics273a_winter08/lectures/lecture14.pdf>Loss functions</a></li>\n<br>\n\n"},{"config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/markdown","editorHide":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1459698117169_-1477273268","id":"20160403-114157_1451741176","dateCreated":"Apr 3, 2016 11:41:57 AM","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:169","dateUpdated":"Apr 3, 2016 2:43:53 PM","dateFinished":"Apr 3, 2016 2:43:53 PM","dateStarted":"Apr 3, 2016 2:43:53 PM","result":{"code":"SUCCESS","type":"HTML","msg":"<hr />\n<h3>Question 11.3</h3>\n<p><i>Generate 2 sets of linearly separable data with 100 data points each using the data generation code provided below and plot each in separate plots. Call one the training set and the other the testing set.</i></p><br>\n<pre><code>def generateData(n):\n \"\"\" \n  generates a 2D linearly separable dataset with n samples. \n  The third element of the sample is the label\n \"\"\"\n xb = (rand(n)*2-1)/2-0.5\n yb = (rand(n)*2-1)/2+0.5\n xr = (rand(n)*2-1)/2+0.5\n yr = (rand(n)*2-1)/2-0.5\n inputs = []\n for i in range(len(xb)):\n  inputs.append([xb[i],yb[i],1])\n  inputs.append([xr[i],yr[i],-1])\n return inputs</code></pre><br>\n<p><i>Modify this data generation code to generating non-linearly separable training and testing datasets (with approximately 10% of the data falling on the wrong side of the separating hyperplane. Plot the resulting datasets. <b>Note</b>: For the remainder of this problem please use the non-linearly separable training and testing datasets.</i></p><br>\n<p><i>Using MLLib  train up a LASSO logistic regression model with the training dataset and evaluate with the testing set. What a good number of iterations for training the logistic regression model? Justify with plots and words. </i></p><br>\n<p><i>Derive and implement in Spark a weighted  LASSO logistic regression. Implement a convergence test of your choice to check for termination within your training algorithm. </i></p><br>\n<p><i>Weight the above training dataset as follows:  Weight each example using the inverse vector length (Euclidean norm): </i></p><br>\n<pre><code> weight(X)= 1/||X||, \n\nwhere ||X|| = SQRT(X.X)= SQRT(X1^2 + X2^2)\n</code></pre><br>\n<p><i>Here X is vector made up of X1 and X2. Evaluate your homegrown weighted  LASSO logistic regression on the test dataset. Report misclassification error (1 - Accuracy) and how many iterations does it took to converge. Does Spark MLLib have a weighted LASSO logistic regression implementation. If so use it and report your findings on the weighted training set and test set. </i></p>\n<h4>Solution:</h4>\n"},"text":"%md \n\n-----\n\n### Question 11.3 ###\n\n<p><i>Generate 2 sets of linearly separable data with 100 data points each using the data generation code provided below and plot each in separate plots. Call one the training set and the other the testing set.</i></p><br>\n\n<pre><code>def generateData(n):\n \"\"\" \n  generates a 2D linearly separable dataset with n samples. \n  The third element of the sample is the label\n \"\"\"\n xb = (rand(n)*2-1)/2-0.5\n yb = (rand(n)*2-1)/2+0.5\n xr = (rand(n)*2-1)/2+0.5\n yr = (rand(n)*2-1)/2-0.5\n inputs = []\n for i in range(len(xb)):\n  inputs.append([xb[i],yb[i],1])\n  inputs.append([xr[i],yr[i],-1])\n return inputs</code></pre><br>\n\n<p><i>Modify this data generation code to generating non-linearly separable training and testing datasets (with approximately 10% of the data falling on the wrong side of the separating hyperplane. Plot the resulting datasets. <b>Note</b>: For the remainder of this problem please use the non-linearly separable training and testing datasets.</i></p><br>\n\n<p><i>Using MLLib  train up a LASSO logistic regression model with the training dataset and evaluate with the testing set. What a good number of iterations for training the logistic regression model? Justify with plots and words. </i></p><br>\n\n<p><i>Derive and implement in Spark a weighted  LASSO logistic regression. Implement a convergence test of your choice to check for termination within your training algorithm. </i></p><br>\n\n<p><i>Weight the above training dataset as follows:  Weight each example using the inverse vector length (Euclidean norm): </i></p><br>\n\n<pre><code> weight(X)= 1/||X||, \n\nwhere ||X|| = SQRT(X.X)= SQRT(X1^2 + X2^2)\n</code></pre><br>\n\n<p><i>Here X is vector made up of X1 and X2. Evaluate your homegrown weighted  LASSO logistic regression on the test dataset. Report misclassification error (1 - Accuracy) and how many iterations does it took to converge. Does Spark MLLib have a weighted LASSO logistic regression implementation. If so use it and report your findings on the weighted training set and test set. </i></p>\n\n#### Solution: ####"},{"config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1459708959291_2029340463","id":"20160403-144239_629583784","dateCreated":"Apr 3, 2016 2:42:39 PM","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:412","text":"%pyspark \n\nimport numpy as np \nimport matplotlib\nmatplotlib.use('Agg')\nimport matplotlib.pyplot as plt\nimport StringIO\nimport urllib, base64\nimport json\nfrom random import shuffle \n\nfrom pyspark.mllib.classification import LogisticRegressionWithSGD, LogisticRegressionModel\nfrom pyspark.mllib.regression import LabeledPoint\n\n# Plotting \ndef showMPL(plot):\n    img = StringIO.StringIO()\n    plot.savefig(img, format='png')\n    img.seek(0)\n\n    uri = 'data:image/png;base64,' + urllib.quote(base64.b64encode(img.buf))\n    print \"%html <img style='width:600px' src='\" + uri + \"'/>\"\n\n# Labels \ndef addLabel(value, switch=False):\n\n\t\"\"\" Does a progressive switch. \"\"\"\n\n\tnewValue = value\n\n\tif np.random.randint(9) == 0: \n\t\t\n\t\tif switch: \n\t\t\tnewValue.append(1)\n\n\t\telse: \n\t\t\tnewValue.append(0)\n\n\telse: \n\t\tif switch: \n\t\t\tnewValue.append(0)\n\n\t\telse: \n\t\t\tnewValue.append(1)\n\n\treturn newValue\n\t\n\n# Create data \nset1 = np.random.normal(loc=-3, size=(100, 2)).tolist()\nset2 = np.random.normal(loc=3, size=(100, 2)).tolist()\t\n\nlabeledSet1 = map(lambda x: addLabel(x), set1)\nlabeledSet2 = map(lambda x: addLabel(x, switch=True), set2)\n\nset1 = np.array(labeledSet1)\nset2 = np.array(labeledSet2)\n\ndata = np.concatenate((set1, set2), axis=0).tolist()\n\nsetA = np.array( [x for x in data if x[2] == 0])\nsetB = np.array([x for x in data if x[2] == 1])\n\n# Clear and plot \nplt.clf()\nplt.title('Generated Data')\nplt.plot(setA[:, 0], setA[:, 1], 'r.', setB[:, 0], setB[:, 1], 'b.')\nshowMPL(plt)\n\n# Prep \ndata = [LabeledPoint(x[2], x[:2]) for x in data]\ntrainingSet = np.random.choice(data, 140)\ntestingSet = np.random.choice(data, 60)\n\ntrainingSet = sc.parallelize(trainingSet)\ntestingSet = sc.parallelize(testingSet)\n\n# Build model \nmodel = LogisticRegressionWithSGD.train(trainingSet, regType=\"l1\")\n\n# Evaluate\nlabelsAndPreds = testingSet.map(lambda p: (p.label, model.predict(p.features)))\ntrainErr = labelsAndPreds.filter(lambda (v, p): v != p).count() / float(testingSet.count())\nprint(\"Testing Error = \" + str(trainErr))\n\n","dateUpdated":"Apr 3, 2016 3:15:43 PM","dateFinished":"Apr 3, 2016 3:15:46 PM","dateStarted":"Apr 3, 2016 3:15:44 PM","result":{"code":"SUCCESS","type":"HTML","msg":"<img style='width:600px' src='data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAyAAAAJYCAYAAACadoJwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAPYQAAD2EBqD%2BnaQAAIABJREFUeJzs3Xl4lOW9//HPJIEQICwBAmEpacJWRaRBKJpY3Kr2VFFBhFRLPWDqzxakaE%2B1ilpQjnBOCwj01KWVpdDUS85oix4PLSgibggoXgdRAikgIU4QkEUjBPL8/hgSMllne9Z5v66LazpPZvkmz7R9PnN/7/v2GYZhCAAAAAAskGR3AQAAAAASBwEEAAAAgGUIIAAAAAAsQwABAAAAYBkCCAAAAADLEEAAAAAAWIYAAgAAAMAyBBAAAAAAliGAAAAAALAMAQQAAACAZQggAAAAACxDAAEAAABgGQIIAAAAAMsQQAAAAABYhgACAAAAwDIEEAAAAACWIYAAAAAAsAwBBAAAAIBlCCAAAAAALEMAAQAAAGAZAggAAAAAyxBAAAAAAFiGAAIAAADAMgQQAAAAAJYhgAAAAACwDAEEAAAAgGUIIAAAAAAsQwABAAAAYBkCCAAAAADLEEAAAAAAWIYAAgAAAMAyBBAAAAAAliGAAAAAALAMAQQAAACAZQggAAAAACxDAAEAAABgGQIIAAAAAMsQQAAArpSdna2cnBy7ywAARIgAAgARKCkp0T333KNhw4apS5cuat26tbp06aKRI0fq3/7t37R161a7S7TNsmXLlJSUpOXLl1vyfj6fL6LHZ2dnKykpqfZf69at1bVrVw0ZMkQTJ07UqlWrVFVVFZfaXn/9dSUlJWnWrFlxeT0A8JIUuwsAALeYOXOmHn30URmGoby8PE2YMEEZGRk6fvy4PvzwQy1evFjz5s3T4sWLddddd9ldri0iDQVW8vl88vl8mjZtmjp16qTq6modO3ZMn3zyiV588UWtWLFC/fv314oVKzR8%2BHC7ywUAzyKAAEAYZs6cqZkzZ6pv374qLi7WyJEjGzzm888/14IFC3T06FEbKrSfYRh2lxCWn//85/rGN74Rcuz48eN66KGHtHDhQl1zzTV65513NGDAgKjfwy1/CwCwAy1YANCCf/7zn5o9e7ZSU1P1yiuvNBo%2BJKlr16567LHH9Mtf/rLBzyorK/X444/r29/%2Bttq3b6/09HRdcskl%2Bstf/tLgsXXbd7Zt26Yf/OAH6ty5s9q1a6fLLrtMb7/9dqPvf%2BbMGf3Xf/2XLr74YnXs2FHt2rVTXl6efve73zW4IN67d6%2BSkpI0adIklZSUaPz48erevbuSk5O1YcMGSdLWrVs1bdo0DR06VF26dFFaWpoGDBigX/ziF/riiy9CXu/yyy/XpEmTJEm33357bZtTcnKy9u3bF1WNNRYvXqzBgwcrLS1NvXv31tSpU3Xs2LFGHxut9PR0LViwQBMnTtQXX3yh%2B%2B%2B/P%2BTnJSUluv/%2B%2BzV8%2BHBlZmaqTZs2ys7O1p133qmysrKQx/7rv/6rrrjiCvl8Pv36178O%2BVvU/G2PHTum//zP/9SVV16pPn36KDU1VZmZmbrhhhv0zjvvxPV3AwCnYQQEAFrw7LPP6vTp05owYYIGDRrU4uOTkkK/2zl69Kguv/xybdu2TXl5eZo8ebKqq6u1Zs0a/fCHP9RHH33U6FyB9957T3PnztUll1yioqIi7du3T6tWrdJVV12lDz74QP3796997OnTp3Xdddfp73//uwYNGqRbb71Vbdq00WuvvaapU6dq06ZNWrZsWYP32LVrl77zne9o4MCBuu2221RZWakOHTpIkp555hm9%2BOKLGjVqlL73ve%2BpurpaW7Zs0bx58/S///u/evfdd9WuXTtJwYvuzp07669//atuvPFGDR06VFKw7alTp05R1zht2jQtWrRIPXv21J133qlWrVrpr3/9q959912dOnVKqampLZ6PSDz88MNavny5XnrpJZ04cULt27eXJPn9fj399NO6/PLLlZ%2Bfr9atW2v79u36wx/%2BoJdeekmbN29WVlaWJOmmm26Sz%2BfT0qVLddlll%2Bmyyy6rff3s7GxJ0o4dOzRjxgyNGjVK1113nTp37qx9%2B/bpb3/7m1555RW99NJLuvrqq%2BP6uwGAYxgAgGZdccUVRlJSkvHss89G9fwf//jHRlJSkvGb3/wm5PjJkyeNa6%2B91khOTja2bdtWe3z9%2BvWGz%2BczkpKSjOXLl4c856mnnjJ8Pp/xs5/9LOT4I488Yvh8PmPatGlGdXV17fHq6mpj8uTJRlJSkvG3v/2t9viePXtq32PGjBmN1r1v376Q16rx7LPPGj6fz/iP//iPkONLly41kpKSjGXLljX6epHW%2BNZbbxk%2Bn88YMGCA8cUXX4T83S6%2B%2BGLD5/MZ3/zmNxt9r8ZkZ2cbSUlJxt69e5t9XJ8%2BfYykpCRj/fr1tccOHDhgnDp1qsFj//GPfxjJycnGT3/605DjNedw5syZjb7HsWPHjEOHDjU4XlZWZvTs2dM477zzwvmVAMCVaMECgBZ89tlnkqRevXo1%2BNnevXv161//unaOyMyZM/XEE0/U/vzw4cNauXKlLrroIt17770hz23durXmzp2r6upq/fnPf27w2gUFBfrRj34UcmzSpElKSUnRpk2bao8ZhqHFixcrKytL8%2BbNC5kI7vP59Nvf/laStHLlygbv0b17dz388MON/t59%2BvRpdFL57bffrg4dOmjNmjWNPq8x0dT47LPPyufz6cEHH1THjh1rj7du3VqPP/542O8dqZrzfPDgwdpjWVlZatWqVYPHXnXVVTr//PMj%2BltIwZavjIyMBsd79uypm2%2B%2BWR9//LH2798fYeUA4A60YAFADPbs2aNZs2bVXlAbhqHs7GxNmzZNUrCN6syZM/L5fJo5c2aD5586dUpSsCWnvmHDhjU4lpKSou7du%2BvIkSO1x3bu3KnDhw9rwIABevTRRxs8xzAMpaWlNfoeF154YaMX1lKwZerJJ5/Uc889p48%2B%2BkhHjx5VdXV17c/rz31oTjQ1vv/%2B%2B5Kk7373uw0eX1BQoOTk5LDfPxLG2bko9cPXihUrtGzZMm3btk1HjhzRmTNnan8WTSvYm2%2B%2BqSeeeELvvPOOKioqaj8LNe9dVlam3r17R/lbAIBzEUAAoAU9evTQxx9/rAMHDjT42ahRo2ovyqurq5WSEvo/q4cOHZIUDCLvvfdeo6/v8/n05ZdfNjheM3eivpSUlJCL35r3KCkpaXbficbeo0ePHk0%2B/pZbbtGLL76o3Nxc3XjjjerRo0fthfb8%2BfN18uTJJp9bXzQ11qwm1r179waPS05OVteuXcN%2B/0jUnOdu3brVHps%2BfbqeeOIJ9ezZU9dee6169eqltLQ0SdKSJUtCJtqH44UXXtC4ceOUlpam733ve8rNzVW7du2UlJSk1157TRs2bIjo7wsAbkIAAYAW5Ofn67XXXtO6det0%2B%2B23N/k4o5FVnGpah6ZPn67f/OY3ptRX8x433XSTVq1aFdFzm9q3Y8uWLXrxxRd19dVX63/%2B539CJtYbhqG5c%2BeaXmPNcwKBQO3k7RpnzpzR559/rj59%2BkRUR0t2796t/fv3q1WrVrUjUAcPHtSiRYs0ZMgQvfXWW2rbtm3Icxprn2vJQw89pNTUVG3ZsqXBcr8HDhyoXS0LALyIOSAA0ILbb79dKSkpWrVqlT755JOInjtixAglJSXpjTfeMKk6adCgQerUqZPeeeedkJGRWOzatUuSdP311zdY1evdd99VZWVlg%2BckJyfLMIxGa4imxry8PEnBZYnre%2BONN%2BL2u9ZV0yY3evTo2hW%2BSktLVV1dre9973sNwsf%2B/ftVWlra4HVq2sOaqnH37t0677zzGoQPwzBM/awAgBMQQACgBTk5OZoxY4ZOnjypa6%2B9tsl9OOrOy6jRrVs33Xrrrdq8ebMee%2ByxkDkUNUpLS7Vnz56o60tOTtbUqVN14MABTZ06VV9//XWDx3z22WeNzgFpSs2Iw/r160OOV1RUaMqUKY0%2Bp0uXLpLUaDtSNDXefvvtMgxDs2fPDvnbfv311/rVr34V9u8SjuPHj%2Bvuu%2B/WihUrlJGRETLJveZvsXHjxpDzd%2BLECRUVFen06dMNXq%2B5v0XNa5aUlNQucFDjkUceieg8AYAb0YIFAGGoWSnq0UcfVX5%2BvoYNG6YRI0YoIyNDX3zxhfbs2aO1a9fK5/Np1KhRIc9dvHixdu3apUceeUR/%2BtOfVFBQoO7du%2BvAgQPasWOHNm/erOLi4gZtRpF46KGH9OGHH%2Bqpp57S6tWrdcUVV6hXr16qqKhQSUmJ3nzzTf37v/%2B7vvWtb4X1esOHD1d%2Bfr78fr/y8/NVUFCgQCCgV155RYMGDVLPnj0bPOfiiy9W27ZttWDBAn3%2B%2Bee180vuvvtupaenR1zjJZdcoqlTp9ZuRHjzzTfX7gOSkZFRu%2B9GpObPn69OnTrJMAwdO3ZMn3zyiTZs2KCvvvpKgwYN0ooVK9SvX7/ax3fv3l0TJkzQc889p6FDh%2Brqq6/W0aNH9Y9//ENpaWkaOnSotm3bFvIeAwcOVK9evfSXv/xFKSkp6tu3r3w%2BnyZOnKg%2Bffpo%2BvTpuuuuuzR06FCNHTtWrVq10ptvvqkdO3Zo9OjRWr16dVS/GwC4gj2r/yaGLVu2GNdff72RkZFhtG3b1hg8eLCxaNEiu8sCEIOdO3ca99xzj/Htb3/b6Ny5s9G6dWujS5cuxogRI4x7773XeP/99xt9XlVVlfG73/3OyM/PNzp16mS0adPG6Nu3r3HVVVcZCxcuNA4fPlz72PXr1xtJSUnGrFmzGn2t7OxsIycnp9GfrVixwrjqqquMLl26GKmpqUbv3r2NSy%2B91JgzZ46xf//%2B2sft2bPHSEpKMiZNmtTk73rkyBHjZz/7mfHNb37TSEtLM/r162fMmDHDqKysbLKGNWvWGJdccomRnp5uJCUlNbrvRrg11vjd735nnHfeeUabNm2MXr16GVOnTjWOHTvW7N%2BhMTX7gNT8qzl3Q4YMMSZOnGj4/X6jqqqq0edWVlYaM2bMMPr372%2BkpaUZ3/jGN4ypU6cahw8fNi677DIjOTm5wXM2b95sXHXVVUanTp2M5ORkIykpyXj99ddrf75s2TLj29/%2BttG%2BfXujW7duxtixY43/%2B7//M3796183eCwAeInPMBqZNYmY/f3vf9fo0aOVl5en8ePHq3379tq9e7eqq6s1Z84cu8sDAAAAbEEAMcHx48c1YMAAFRQU6Pnnn7e7HAAAAMAxmIRugpUrV6qiokKzZ8%2BWJH311VeNLs8JAAAAJBoCiAnWrVunDh066NNPP9WgQYPUvn17dejQQT/96U/ZWAoAAAAJjQBigpKSElVVVemGG27Q97//ffn9fk2ePFlPPvmkJk2aZHd5AAAAgG2YA2KCfv366Z///KfuuusuLV68uPb4XXfdpaefflo7d%2B5Ubm6ujRUCAAAA9mAfEBOkpaVJkiZMmBBy/Ic//KGeeuopvf32240GkM8//1xr1qxRdnZ27WsAAADAOSorK7Vnzx5dc8016tq1q93luBIBxAQ9e/bURx99pO7du4ccz8zMlNT4bsmStGbNGt12222m1wcAAIDYrFixQrfeeqvdZbgSAcQEw4YN09q1a1VWVqb%2B/fvXHj9w4IAkqVu3bo0%2Br2YX5BUrVoS9WzGsM336dM2fP9/uMtAEzo9zcW6ci3PjbJwfZ9qxY4duu%2B222us2RI4AYoJbbrlFc%2BbM0R//%2BEdddtlltcefeeYZtWrVKuRYXTVtV9/61reUl5dnQaWIRMeOHTkvDsb5cS7OjXNxbpyN8%2BNstMtHjwBigqFDh2rSpElasmSJqqqqNGrUKL322mv67//%2Bbz3wwAPq0aOH3SUCAAAAtiCAmOSpp55S3759tWTJEr344ovq27evFixYoKlTp9pdGgAAAGAbAohJkpOT9dBDD%2Bmhhx6yuxQAAADAMdiIEAhTYWGh3SWgGZwf5%2BLcOBfnxtk4P/AqNiJ0kK1bt2rYsGHasmULk84AAAAciOu12DECAgAAAMAyBBAAAAAAliGAAAAAALAMAQQAAACAZQggAAAAACxDAAEAAABgGQIIAAAAAMsQQAAAAABYhgACAAAAwDIEEAAAAACWIYAAAAAAsAwBBAAAwAqBgFRQIOXmBm8rKuyuCLAFAQQAAMAKY8dKb74plZYGb8eMsbsiwBYEEAAAACuUlzd/H0gQBBAAAAArZGU1fx9IECl2FwAAAJAQ/P5g21V5eTB8%2BP12VwTYggACAIDdAoHg/IC6F6aZmXZXhXjLzJQ2brS7CsB2tGABAGA3JicDSCAEEAAA7MbkZAAJhAACAIDdmJwMIIEwBwQAALsxORlAAiGAAABgNyYnA0ggtGABAAAAsAwBBAAA2C8QkAoKpNzc4G1Fhd0VATAJAQQAANiPpYiBhEEAAQAA9mMpYiBhEEAAAID9WIoYSBisggUAAOzHUsRAwiCAAAAA%2B7EUMZAwaMECAAAAYBkCCAAAAADLEEAAAAAAWIYAAgAAUAd7IgLmIoAAAADUwZ6IgLkIIAAAIPE0M8zBnoiAuQggAAAg8TQzzMGeiIC5CCAAACDxNDPM4fdL%2BflSTk7w1pQ9Ea2YaMJkFjgUGxECAIDEk5UVHP2oe/8sS/ZErBmBkYJ1jBkT/ze14j2AKBBAAABA4vH7gxfk5eXB8GHKMEczrJhowmQWOBQtWAAAIPHUDHPs3h28zcwM73nxamuyYqIJk1ngUIyAAAAAhCtebU1WjMDYPcoDNIEAAgAAEK54tTVZMdHEksksQORowQIAAAgXbU1AzBgBAQAACBdtTUDMGAEBANiHfQrgts9AtJPXAdQigAAA7NPMbtRIEHwGgIRDAAEA2Id9CsBnAEg4BBAAgH2Y0Bs9t7UuNYXPAJBwCCAAAPv4/VJ%2BvpSTE7xlQm/4vNK6ZOdnwCshDnAZVsECANiHfQqi55XWJTs/A/HaVBBARBgBAQDAjWhdip1XQhzgMgQQAADciPa12BHiAFvQggUAgBvRvhY7NhUEbMEIiEVmz56tpKQkDRkyxO5SAACAxKaCgE0IIBYoKyvT448/rvbt29tdCgAAAGArWrAscO%2B99%2Briiy/W6dOndejQIbvLAQAAAGzDCIjJNmzYIL/frwULFthdCgAAAGA7AoiJqqurdffdd6uoqEjnn3%2B%2B3eUAAGA/Nv8DEh4BxES///3vtW/fPj366KN2lwIAgDPYsYN7TejJzpY6dAjeWh1%2BCF5ALeaAmOTw4cN65JFH9PDDDysjI8PucgAAcAY7Nv%2Bru%2BO5JB0/Lu3da%2B3O5%2By6DtRiBMQkDz74oLp06aIpU6bYXQoAAM5hx%2BZ/TYUcK3c%2BjzV4MYICD2EExAS7du3SM888oyeeeEJlZWWSJMMw9PXXX6uqqkp79%2B5Vhw4d1Llz50afP336dHXs2DHkWGFhoQoLC02vHQAAU9mx%2BV9WVnDUobHjVqlfQ6TvzQiKLYqLi1VcXBxy7OjRozZV4x0%2BwzAMu4vwmtdff11XXHGFpGDwqM/n82natGmaN29eyPGtW7dq2LBh2rJli/Ly8iypFQAAz6uoCF6w798vHToknTol%2BXzShRdKq1dbswFhTQ11g1ck75ubGxpgcnKCGyjCclyvxY4REBMMHjxYL7zwQoPjDz74oE6cOKGFCxcqJyfHhsoAAEhANTueS8H2pZqRhE2brBtJqFtDNGIdQQEchABigi5dumj06NENjs%2BfP18%2Bn0/XX3%2B9DVUBAABbJsHHgx2ta4BJCCAW8/l8dpcAAEDiCASC8yfKy6WuXYP363LLSEKsIyiAgxBALPTaa6/ZXQIAAIml/uTtutLToxtJqBtqopnPASQ4luEFAADneG251%2BZarLp1iy442LGZYnO8ds7geQQQAABwjtMurmPVXItVtO1XTptH4rVzBs%2BjBQsAAJzjtIvrWNWdvN21q2QYwaV4I5jI3aDjqsu3lOmkFam8ds7geQQQAADcyKx5CF5b7jUOk7cb7AE4wq%2BN%2BVc4Z0Uqr50zeB4BBAAANzJrZ%2Bxol3v12MTsur9OWVnoz8o/by3tdtCKVCzRC5chgAAA4EZmtd1EO2JgViBqjAVhp%2B6vU5/jBhhYohcuwyR0AADcqP5VsN1XxVEGoqgWcLJg0nX98lNTpZwcKT%2BfAQYgVgQQAADcyO8PXg075ao40kB0NnmM7bs58ixhwaTr%2BuVfdJG0e3dwoCHswRaWxwUaRQsWAABuZGfbTWMtUJHOQzg7ilGuziGHw8oSsU66DqOFK%2BZpFYGA1L%2B/dPx48L7ZbWmAixBAAABAZJqa7xHJxfXZpJGlcpUqt/ZwWFki1nQQxnyVmPPd2LHnwkcNlscFJNGCBQCAfaJp0XFCW088WqDOJg2/xihfG5WTWhZ%2BJ1lNOoi4J6qJes0IBo29pt3zdACHIIAAAGCXliZTNxY2nLDrdTwmwJ%2Bdw5KZk66N%2Bfdr975WUWWJqFgxgb/%2Ba6an2z9PB3AIWrAAALBLS9/EN9YqVP8x774bDCdW7rsRj30n7JzDYsW%2BGY29h9P3RfHYXi5wLgIIAAB2aWkydWMBpf5zTp8%2BNxJi1QW92/edsKL%2BWN8jljAQ7XOt3MsFCY0WLAAA7NLSUrqNtQrVPCel3neITHB2hnjN0Yml1S7a51oxNwYQIyAAANinpW/Jm2rj2bgxeHFbd6tuJjg7Q7xGEWIJA9E%2BN9bljYEwEUAAAHCq5gKKFfMYELl4jSLEEgaifS6fKViEAAIAgBsZht0VxMarE57jNYoQSxiI9rlun9sD1yCAAADgRk6bMBxpoHBC/WaEoHAu/sN531jCAEECDkcAAQDAjZw2YTjSQOGE%2Bs0IQeFc/DshfAE2YhUsAADcyIrN9CIRaaBwQv12haAm3tcJm9wDViCAAADgRi0t4WulQEA6eDD0WEuBwgn12xWCmnhfJ2xyD1iBFiwAANzISX3%2BY8dKx4%2Bfu5%2Be3nKgsKv%2BuvMvunSRRoyQPv88vqs%2BtTTHo4l5IqYNyHh1wj9ciwACAABiU/9KuVs3517g1p9/kZ8v7d5t7nvUn%2BPRRPgybRsO5pzAYWjBAgDAa6yeTGBFK1O8ficr5n1E%2BR6mdaU5YcI/UAcjIAAAeI3V33hbsYFdvH4nK3b7jvI9TOtKY4dzOAwBBAAAr7H6G28r5nPE63fy%2B6Xrr5e2bQveP3UqOJoSz5Yxp%2B0o7rR6kPAIIAAAeI0Xv/GO1%2B%2BUmSm1aiWdPBm8/9578R8hctICAZLz6kHCYw4IAABeUHeORFWVNHy4M5bojUQgoMCI61XQZrNy25Sp4Dunzk31qJkg0bdvcJWt/fujnwtSf/Tk00/ZgAOwECMgAAB4gRWrO5lt7FiNfW%2BO3tRFkqTSTXUGJ2q%2BxS8okPbuDS77u3ev1K9fcNWtSJaXrT%2BacuSItG9f8D%2BzShRgOkZAAADwAi%2BsdFRernJl1T/U4DEhjh%2BPfOe%2B%2BstNZWQ0/x4A4ooAAgCAF9i1q3c8ZWUpS%2BX1DzV4TJPCDQ41oym7dwdve/cO/z3qsnq5Y8AjCCAAAHiBaZtIWMjvl3/4HOWnblZOapnyR5xq%2BGvU/T3T00N/Fm3oivRvVxM8%2BvYNjrxEOgIDJDjmgAAA4AVeWOkoM1OZm15Ss79F3d%2BzoiK25WUDgeDcmZrnv/12eHNI6s63qYvWLSAsBBAAAOBOsYauaDc3bCpouLHtDbABLVgAACAyNS1I2dlShw7BWzfOgYh24n79oOHzSSNGOLPtjXkqcCACCAAAiEzNyEHd5XDdOAeipYn7TV28%2B/2h808MI7i5YTx3U4%2BXmnPFPBU4CC1YAAAgMk2NFLhtDoTf3/wckqZatDIzg3uPHD9%2B7rFO/d29sDwzPIcAAgAAIlN/I7%2B6x92kpTkkzV281/8bOPV3d0udSCgEEAAAEL5AQKqqklJTg/dTUqSuXYN7aThxDkSk6q6MdfBg6M/qXry3NHriFG6pEwmFAAIAAMI3dqy0adO5%2BxddFN/lf%2Bsvjev3Wzu3ov4Su%2BnpwXar%2BhfvFix7HJc/hReWZ4bnEEAAAED4zJ5TEO3SuPFS//fp1i24Y7oN7P5TAGZhFSwAABC%2BllaOipVZASfc5WjN/v0iwPxxeBUBBAAAhM/vl/LzpZyc4G285xSYFQDCXY7W7N8vApZmIfYLgYVowQIAAOFrbE5BPOdt1Js0HXjyBY0tiMNLhzuc4KA5E5bOH7ey38vueT6wHQEEAADEJp4Xr/UCwNiCOL20C5ejtTQLWdnvxeSWhEcLFgAAiI2JF69xe2kHtVY5Ujz6vcJt42JyS8JjBAQAAMTGxNGFuL20g1qrHCke/V7hjmy4cDQK8UUAAQAAsWns4jVOff7so2eReAS0cEc2OKkJjwACAABi09jFa0F8Jm94ZuAiESZehzuy4ZmTimgRQAAAQPzR5x8qESZeM7KBMBFAAABA/CVyn39jox2JEMgY2UCYWAULAOB9bLJmvURedaqxTQ/rB7CDB/k8ImExAgIA8L5EaH9xmkT%2BNvzTT0Pv798vbdp0rj3p4EHp%2BPHgPz6PSECMgJhg8%2BbNmjJligYPHqz27durb9%2B%2BGj9%2BvEpKSuwuDQASUyK0vzhJoo84HTkSev/w4XOBbPduqVu30J/zeUSCIYCYYO7cuXrhhRd01VVXaeHChbrzzju1YcMG5eXl6aOPPrK7PABIPPHYZA3ha6wFyaliDUuNPT8jI/Qx9e/zeUSCowXLBPfee6%2BKi4uVknLuz3vLLbfoggsu0Jw5c7R8%2BXIbqwOABMTqPNZy04hTrO15jT2/d29p795zj%2BndO/Q5fB6R4AggJhg5cmSDY/369dP555%2BvHTt22FARACS4RJ6PYAc3rYAVa1hq7Plvv918wODziARHC5aFAoGAunbtancZAACYK14rYFkxlyTWdqjGnl93vsfGjd7bcBCIESMgFlmxYoXKysr02GOP2V0KAADmitc3/FasXhZrOxTtVEDECCAW%2BPjjjzVlyhTl5%2Bdr4sSJdpcDAIA7WDGXJNawRDsVEDFasEwWCAT0gx/8QJ07d9bzzz8vn89nd0kAgES1FZOGAAAgAElEQVTj1mVxWS3KHG79PMAzGAEx0bFjx3Tttdfq2LFj2rhxo3r06BHW86ZPn66OHTuGHCssLFRhYaEZZQIAvM6tGzHS3mQOt34ebFBcXKzi4uKQY0ePHrWpGu8ggJjk5MmTuu6667Rr1y6tW7dOAwcODPu58%2BfPV15enonVAQASipuWxa2L9iZzuPXzYIPGvgDeunWrhg0bZlNF3kALlgmqq6t1yy236N1339WqVas0YsQIu0sCACQyWpkSW/2Wq/orcvJ5gMUYATHBPffco9WrV2v06NH6/PPPtXLlypCf33rrrTZVBgBISLQyOVsgEGyLqnt%2B4rl0b/2Wq%2BHDg8sj83mATQggJti2bZt8Pp9Wr16t1atXN/g5AQQAHMrsC0G70MrkbGbPyajfYnXoUHCPEsAmtGCZ4LXXXtOZM2ea/AcAcKiaC8HS0uDtmDF2V4REYPacDFrw4DAEEAAAajA5F3YwOyDEa2d6IE5owQIAoEZWVnD0o%2B59wGxmz9GhBQ8OQwABAKAGk7VhBwICEgwBBACAGlwIAoDpmAMCAAAAwDIEEAAAEL36m9xVVNhdEQCHI4AAAIDosXQxgAgRQAAAQPRYuhhAhAggAAAgemxyByBCrIIFAACix9LFACJEAAEAANFj6WIAEaIFCwAAAIBlCCAAAMA9WPYXcD0CCAAAcA%2BW/QVcjwACAADcg2V/AdcjgAAAAPdg2V/A9VgFCwAAuAfL/gKuRwABAADuwbK/gOvRggUAAADAMgQQAAAAAJYhgAAAAGdj7w/AUwggAADA2dj7A/AUAggAAHA29v4APIUAAgAAnI29PwBPYRleAADgbOz9AXgKAQQAADgbe38AnkILFgAAAADLEEAAAAAAWIYAAgAA0BT2IAHijgACAADQFPYgAeKOAAIAANAU9iAB4o4AAgAA0BT2IAHijmV4AQAAmsIeJEDcEUAAAACawh4kQNzRggUAAADAMgQQAAAAJ2MpYHgMAQQAAMDJWAoYHkMAAQAAcDKWAobHEEAAAACcjKWA4TGsggUAAOBkLAUMjyGAAAAAOBlLAcNjaMECAAAAYBkCCAAAAADLEEAAAAAAWIYAAgAAAMAyBBAAAAAAliGAAAAAALAMAQQAAACAZQggAAAAACxDAAEAAABgGQIIAABwl0BAKiiQcnODtxUVdlcEIAIEEAAA4C5jx0pvvimVlgZvx4yxuyIAESCAAAAAdykvb/4%2BAEcjgAAAAHfJymr%2BPgBHI4AAMaIVGQAs5vdL%2BflSTk7w1u%2B3uyIAESCAmOTUqVO677771KtXL7Vt21YjR47U2rVr7S4LJqAVGQAslpkpbdwo7d4dvM3MtLsiABEggJjkxz/%2BsRYsWKAf/ehHWrhwoVJSUvQv//Iveuutt%2BwuDXFGKzIAAED4CCAm2LRpk5577jnNmTNHc%2BbM0R133KF169apb9%2B%2B%2BuUvf2l3eYgzWpEBAADCRwAxwapVq5SSkqKioqLaY6mpqZo8ebLefvttlZWV2Vgd4o1WZAAAgPCl2F2AF33wwQcaMGCA2rdvH3J8xIgRtT/v1auXHaXBBDWtyAAAAGgZIyAmKC8vV1YjfThZWVkyDEMHDhywoSoAAADAfgQQE1RWVio1NbXB8TZt2tT%2BHAAAAEhEBBATpKWl6eTJkw2Of/3117U/BwAAABIRc0BMkJWV1WibVfnZ9Vl79uzZ7POnT5%2Bujh07hhwrLCxUYWFh/IoEAABAs4qLi1VcXBxy7OjRozZV4x0EEBMMHTpU69ev14kTJ0Imor/zzjvy%2BXwaOnRos8%2BfP3%2B%2B8vLyzC4TAAAAzWjsC%2BCtW7dq2LBhNlXkDbRgmeDmm2/W6dOn9fTTT9ceO3XqlJYuXaqRI0eyAhYAAAASFiMgJhgxYoTGjRunX/3qVwoEAurXr5%2BWLl2qvXv3asmSJXaXBwAAANiGAGKSP/3pT3rooYe0YsUKHTlyREOGDNHLL7%2Bs/Px8u0sDAAAAbEMAMUnr1q01d%2B5czZ071%2B5SAAAAAMdgDggAAAAAyxBAAAAAAFiGAAIAAADAMgQQAAAAAJYhgAAAAACwDAEEAAAAgGUIIAAAAAAsQwABAAAAYBkCCAAAAADLEEAAAAAAWIYAAsBWgYBUUCDl5gZvKyrsrggAAJiJAALAVmPHSm%2B%2BKZWWBm/HjLG7IgAAYCYCCABblZc3fx8AAHgLAQSArbKymr8PAAC8JcXuAgAkNr8/2HZVXh4MH36/3RUBAAAzEUAA2CozU9q40e4qAACAVWjBAgAAAGAZAggAAAAAyxBAAAAAAFiGAAIAAADAMgQQAK7AjukAAHgDAQRALSdf5LNjOgAA3kAAAVDLyRf57JgOAIA3EEAAlzJjtMLJF/nsmA4AgDcQQACXMmO0wskX%2BX6/lJ8v5eQEb9kxHQAAd2IndMClzBit8PuDQaa8PBg%2BnHSRz47p0QsEgoG17nnNzLS7KgBAoiKAAC6VlRUc/ah7P1Zc5HtTzWiZFPzMjBnDeQYA2IcAAriUk0cr4CxOntsDAEg8BBDApRitQLjMGC0DACBaBBAA8DhGywAATkIAAQCPY7QMAOAkLMMLV3DyDt1wET5IAADYjgACV3DyDt1wET5IAADYjgACV2AVH8QFHyQAAGxHAIErOHmHbrgIHyQAAGzHJHS4Aqv4IC74IAEAYDsCCFyBVXwQF3yQAACwHS1YsBWLEgEAACQWAghsxaJEAAAAiYUAAlslyqJEjPQAAAAEEUBgq0RZlIiRHgAAgCAmocNWibIoUaKM9AAAALSEAAJbJcqiRFlZwdGPuvcBAAASEQEEsECijPQAAAC0hAACWCBRRnoAAABawiR0AAAAAJYhgAAexdK/DfE3AQDAfgQQwKNY%2Brch/iYAANiPAAJ4FEv/NsTfBAAA%2BxFAAI%2BybJNHF/U1JcrGlwAAOBkBBPAov18aPlxKTQ3%2Bq6oyKRu4qK/J75fy86WcnOAtyyEDAGA9luEFPCozU2rdWjp5Mnh/06ZgNoj7csAu6mtiOWQAAOzHCAjgYfHKBs12WdHXBAAAIkAAAepx0ZSGFsUrGzTbZeWiviYvnVsAANyKAGKCV199VZMnT9bAgQPVrl075ebmqqioSJ999pndpSEMLprS0KJ4ZYNmR1Jq%2Bpp27w7eZmZGXa/ZvHRuAQBwK%2BaAmOC%2B%2B%2B7TkSNHNG7cOPXv31%2BlpaVatGiRXn75ZX3wwQfKdPAFGpwxpSEQCF4sl5cHRy38/uiu6%2BM15yErK3jRXve%2BGznh3AIAkOgIICaYP3%2B%2BCgoKQo5dc801GjVqlBYvXqxZs2bZVBnCEdXFdrwSw1k139RLwVqimTwez5L8/mANdV/LjbwSpAAAcDMCiAnqhw9JuvTSS5WRkaEdO3bYUFECC/MqvO7DunYNLl976FAEF9vxSAx1xOOb%2BniW5JXVoyINUnHOlQAAQAQQy3z55Zc6ceKEunbtancpiSXMq/D6D8vPD05pCFuce3vi8U097UYNRRqk4pwrAQCAmIRumfnz56uqqkoTJkywu5TEEuZVeMwX63Feirbu5PHhw4ObCEa6clNLJbEiVMsIcQAAxB8BpAWGYejkyZNh/WvKhg0bNGvWLI0fP16jRo2ysHqEGwzqD0xFPFAV56Vo6y4s1bp1cBPBSFduaqkkVoRqGVucAAAQf7RgtWDDhg26/PLLW3ycz%2BfTjh07NGDAgJDjH3/8scaMGaMhQ4bomWeeMatMNCXMpn/DaP5%2Bi0ycJBHtt/AtlcS3%2By3zyuR7AACchADSgkGDBmnp0qVhPTar3tejn376qa6%2B%2Bmp17txZL7/8stq1axfW60yfPl0dO3YMOVZYWKjCwsKwno86wgwGhw41fz9S8Zy8bNbKTawI1TKvTL4HAESnuLhYxcXFIceOHj1qUzXe4TOMiL/rRRgOHz6s/Px8HT16VBs3blROTk6Lz9m6dauGDRumLVu2KC8vz4IqvSPWC/6CgnOTjaVgy1IsF56Nvt5/R1dkRUXDb%2BHjsRKTWa9rFVaoAgDYgeu12DECYoKvvvpK3//%2B91VeXq7169eHFT4Qm1hXK4p3q02j7U1RFmnWt/Bu/3afFaoAAHAnAogJfvjDH%2Bq9997T5MmTtX37dm3fvr32Z%2B3bt9cNN9xgY3XeFOt8hnhfjDfa3sSkiwZiGcXgzwkAgDsRQEywbds2%2BXw%2BPfvss3r22WdDfta3b18CiAmcNp%2Bh0RGVMeEXmSjtRbGMYjjtnAMAgPAQQEzwz3/%2B0%2B4SEo7TViuqO6ISCJytbf/rykrfLn/GHcrs3brZIhOlvSiWUQynnXMAABAeAgg8wcnzGc6FiWSVaojGDNnUYq2J0l4UyyiGk885AABoGhsRAiaLJkx4YQO8pnZar3u8qiq403uc9m8EAAAuwAgIXM0NcyWi%2BZbfC%2B1FTbWR1T%2Benx/c8R0AACQGAghczQ1zJaIJE15oL2pq5CdR2ssAAEDjaMGCq7nhYrYmTOzeHbx12ghNS5pqpWpJU21kXmgvi1i0f0QAADyIERC4Gkuxmi/aUaamRn680F4WMTcM1QEAYBECCFwtIS9mLRbtKFNTbWReaC%2BLmBuG6gAAsAgBBK6WkBezFmOUKQ74IwIAUIs5IACa5fcHV6piqdyGwp7awR8RAIBajIDAcZy8tK6TazMLo0xNC3tqB39EAABqMQICx6m5qCstDd6OGWN3RefYXRuLKTkLUzsAAIgcAQSO4%2BSLOrtrszsAIVRCLikMAECMCCBwHCdf1Nldm90BKBFEMsrE1A4AACLHHBA4jpOX1rW7NhZTMl8kW3YwtQMAgMgRQOA4Tr6os7s2uwNQImCUCQAAcxFAABdpKgAl4upcZmGUCQAAczEHBGiBG1aeYnJ6/DCvAwAAczECArQgkjkBdmmqbYiRkcjZ3WYHAIDXEUCAFrhhTkD9tqGDB4MjNgcPSsePB485NTwBAIDEQgsW0AK7l94NR922ofT0YOgoLT0XPmo4MTzFwsntcU6uDQAAOzECArTADStP1W0bys1tGDxqODE8xcLJ7XFOrg0AADsRQIAWuG1OQP12rPR0qVs354anWDi5Pc7JtQEAYCcCCOAxjY3YeHXiuZOXzHVybQAA2IkAAniM20ZsYuHk9jgn1wYAgJ0IIABcy8lhy8m1AQBgJ1bBgqlYCQgAAAB1EUBgqkTZoZugBQAAEB4CCEyVKCsBJUrQAgAAiBUBBKaqv/JPWZk3RwiaClqxjowwshIZ/l4AADgfAQSmqtmhOzU1eP/kSW%2BOEDS1W3qsIyOxPD8RL8YZiQIAwPkIIDBVzUpAvXqFHo%2BpFcuBV9Y1QSsnJ3hbs%2BRqrC1osTzf9ItxB56HRGn5AwDAzQggsERTIwRRceDX3DVBa/fu4G3Nxn%2Bx/t6xPN/0i3EHnoe4fs4AAIApCCCwRFMjBFFx0dfcsf7eTz4ppadLKSnB26eeCv%2B50VyMRzSo4cDzENfPGQAAMAUbEcIScd2ULSsr%2BK173fsOFevv/f/%2Bn3T8ePA/Hz8u3XlneK8XCEhVVefm3gwZEt7FeM2ghhT8E48Z08z7NXMeAoHga9XdBbxmVCic2qN9Lpv/AQDgfAQQuI/fH7wyrnuF6lHRDjKMHStt2nTufuvW4V3ER/R%2BzZyHiIJMI7VH%2B1wAAOB8BBC4TwJ9zR3tYE%2B0wSWi92vmPET1/meHPsrf/bOkb0T2XAAA4BrMAQEcLNo5DdFOxo7XHIqo3v/s0EfW6X2RPxcAALgGIyCAg0Uz2BMISKdOnZv/ceGF4QeJWAeXauZv7N8fnDSfkSH17h3m%2B58d6vBrjMbIr/KUbyjrO9/wcocdAAAJiQACz4plMrObjR0rvffeufutWln3e9edvyEFJ7%2BHHWjO9n9l6qA26lLpO/kJ02oHAEAiIYDAsxJ1MrOdq%2BPG9N4JtLgAAACJjDkg8CwHblPRqHhvKG7nZnwxvXdTuzkCAABPIYDAs9yyK3a8NxSP%2B2Z8ESQkuzcCjHeYAwAA8UcLFjzLLR098R6piccqxSHzZw4G5D%2B%2BU5k62GIvm90rJCdq2x0AAG5CAIFn2X0xHC4nbuweciGvIRojf3BiuOTcXjaFH%2BYSdYECAACcgBYswGbhtC1Z3VrU4EJedVKRExJSE8Jtu4t32xsAAAgfIyCAzcIZqWnQWtTvQ23c1cO0r%2B0bjMqkfyl1y3F2L5vCb7tzywIFAAB4EQEEcIEGF8zH25k6waHhhfwQKXO3Ke8VT%2BG23cXS9kb7FgAAsSGAAC7Q4IJZ5aZ%2BbR/L/Bk3XKDHskABE90BAIgNAQRwAb8/2HZVfrydslQuv8ZIWQNifl0zwoIbLtBjCVi0bwEAEBsCCOACmZkKzvmo/dp%2BQFzmYpgRFrx%2Bge7EVcsAAHATAgjgFiasK2xGWPD6Bbpb9pcBAMCpCCBAAjMjLHj9At0t%2B8sAAOBUBBAggZkRFrhABwAAzSGAAAmMsAAAAKzGTuiAw8Rz13Ord1AHAABoCQHEAkVFRUpKStLo0aPtLgUuULMyVWlp8HbMGGe8FhIbYRYAEC8EEJNt3rxZy5YtU1pamt2lwCXiuTKV45bE5SrWtQizAIB4IYCYbNq0afrxj3%2BsTKdtBQ3Hqr8SVSwrU8XzteKCq1jXclyYBQC4FgHERMuXL9f27ds1e/Zsu0uBi/j9Un6%2BlJMTvI1lZap4vlZccBXrWo4LswAA12IVLJOcOHFC999/vx588EFGPxCReK5M5bhVrry%2BS6GHeX1/FwCAdQggJpk5c6batm2rn//853aXEioQCLbB1L2KICB5jmNPM1exruW4MAsAcC0CSAsMw9CpU6fCemxqaqokaefOnVq4cKGee%2B45tWrVyszyIlfTgy8Fv4keM4arCg9y7Gn28lWsY1MfAADOwhyQFmzYsEFpaWkt/mvbtq127twpKTjxvKCgQDfeeKPN1TeCHvyEYMZpZgGrFjDBHgCAsDAC0oJBgwZp6dKlYT02KytLr776qtasWaMXXnhBe/fulRQcRTl9%2BrQqKyu1d%2B9eZWRkKD09vcnXmT59ujp27BhyrLCwUIWFhVH/HnWKpAffJE76AtyM0%2BzYURWnINwDgOcUFxeruLg45NjRo0dtqsY7fIZhGHYX4SXLli3TpEmTVP/P6vP5ZBiGfD6f5s%2Bfr7vvvrvBc7du3aphw4Zpy5YtysvLM6fAioqGPfi0icRFQcG5C3QpuOqUXRfoZpzm3NzQUJOTI%2B3e3fhjnRTGLOOkDwAAwDSWXK95HCMgcXbllVfqhRdeaHC8qKhI2dnZmjFjhgYPHmxDZWd5uQffZk76AtyM0xzJqEpCjpYwwR4AgLAQQOKsd%2B/e6t27d4Pj06ZNU/fu3XX99dfbUBWs4PXutkiur50UxixDuAcAICwEEIv4fD75fD67y4CJ3P4FeEttU5FcX3s9jAEAgOgRQCxSWvdqDJ7k9i/A49k2ZWUYS8j5JgAAuBgBBICk%2BLZNWRnGEnK%2BCQAALsY%2BIAAkNWyTckvbVELONwEAwMUIIAAkBVuX8vODy%2Bvm57tnDotbgxMAAImKFiwAkkLbpgIB92wX4/bJ/wAAJBoCCIAG3DSvwu2T/wEASDS0YAFogHkVAADALAQQIE4CAamgQMrNDd5WVNhdUfQScV6Fl84fAABORgsWECdualtqSSLOq/DS%2BQMAwMkIIECceKltKRHnVXjp/AEA4GS0YAFxkohtS17C%2BQMAwBqMgABxkohtS17C%2BQMAwBoEECBOErFtyUs4fwAAWIMWLDgKKxEBAAB4GwEEjlKzElFpafB2zBi7KwIAAEA8EUDgKKxEBAAA4G0EEDgKKxEBAAB4G5PQ4SisRAQAAOBtBBA4CisROUsgEJyXUzcQZmbaXRUAAHAzWrAANIlFAQAAQLwRQAA0iUUBAABAvBFAADSJRQEAAEC8MQcEQJNYFAAAAMQbAQRAk1gUAAAAxBstWAAAAAAsQwABAAAAYBkCCAAAAADLEEAAAAAAWIYAAnhIICAVFEi5ucHbigq7KwIAAAhFAAE8hJ3LAQCA0xFAAA9h53IAAOB0BBDAQ9i5HAAAOB0bEQIews7lAADA6QgggIewczkAAHA6WrAAAAAAWIYAAgAAAMAyBBAAAAAAliGAAAAAALAMAQQAAACAZQggAAAAACxDAAEAAABgGQIIAAAAAMsQQADERSAgFRRIubnB24oKuysCAABORAABEBdjx0pvvimVlgZvx4yxuyIAAOBEBBAAcVFe3vx9qzASAwCAsxFAAMRFVlbz963CSAwAAM6WYncBALzB7w9e7JeXB8OH329PHU4ZiQEAAI0jgACIi8xMaeNGu6sIhp/S0tD7AADAOQggADzFKSMxAACgcQQQAJ7ilJEYAADQOCahAwAAALAMAQQAAACAZQggAAAAACxDAAFgKjYGBAAAdRFAAJiKjQEBAEBdBBATrV27VldeeaU6deqkDh066KKLLtLzzz9vd1mApdgYEAAA1MUyvCZZsmSJ7rjjDl199dV6/PHHlZycrE8%2B%2BUSffvqp3aUBlmJjQAAAUBcBxAR79%2B7VlClTNG3aNM2bN8/ucgBbsTEgAACoiwBigt///veqrq7WzJkzJUlffvml2rVrZ3NVgD3YGBAAANTFHBATrFu3ToMGDdLLL7%2BsPn36KD09XV26dNHDDz8swzDsLg8AAACwDSMgJigpKVFycrImTZqk%2B%2B67T0OGDJHf79djjz2mM2fOaPbs2XaXCAAAANiCANICwzB06tSpsB6bmpoqSTpx4oQMw9DcuXP1i1/8QpJ000036dChQ3riiSf0wAMP0JIFAACAhEQLVgs2bNigtLS0Fv%2B1bdtWO3fulCSlpaVJkiZMmBDyWoWFhaqsrNT7779v%2Be8BAAAAOAEjIC0YNGiQli5dGtZjs86uL9qzZ0/t2rVL3bt3D/l5ZmamDMPQkSNHmn2d6dOnq2PHjiHHCgsLVVhYGH7hAAAAiElxcbGKi4tDjh09etSmaryDANKC7t27a%2BLEiRE9Z9iwYdq1a5fKysqUnZ1de7ysrEw%2Bn0/dunVr9vnz589XXl5eNOUCAAAgThr7Anjr1q0aNmyYTRV5Ay1YJhg/frwMw9Af//jH2mOGYWjJkiXKyMjgQwugSYGAVFAg5eYGbysq7K4IAID4YgTEBDfccIOuvPJKPf744zp48KAuvPBCvfDCC3rrrbf09NNPq1WrVnaXCMChxo6V3nwz%2BJ9LS4ObOLKPCgDASxgBMclf//pX3X333Vq9erXuueceVVRUaOXKlZo8ebLdpQFwsPLy5u8DAOB2jICYpG3btpo3b57mzZtndykAXCQrKzjyUfc%2BAABeQgABAAfx%2B4NtV%2BXlwfDh99tdEQAA8UUAATwuEAjOK6h7QZuZaXdVaEpmJnM%2BAADexhwQwONqJjWXlgZvx4yxuyIAAJDICCCAxzGpGQAAOAkBBPC4%2BpOYmdQMAADsxBwQwOOY1AwAAJyEAAJ4HJOaAQCAk9CCBQAAAMAyBBAAAAAAliGAAAAAALAMAQQAAACAZQggAAAAACxDAAEAAABgGQIIAAAAAMsQQAAAAABYhgACAAAAwDIEEAAAAACWIYAAAAAAsAwBBAAAAIBlCCAAAAAALEMAAQAAAGAZAggAAAAAyxBAAAAAAFiGAAIAAADAMgQQAAAAAJYhgAAAAACwDAEEAAAAgGUIIAAAAAAsQwABAAAAYBkCCAAAAADLEEAAAAAAWIYAAgAAAMAyBBAAAAAAliGAAAAAALAMAQQAAACAZQggAAAAACxDAAEAAABgGQIIAAAAAMsQQAAAAABYhgACAAAAwDIEEAAAAACWIYAAAAAAsAwBBAAAAIBlCCAAAAAALEMAAQAAAGAZAggAAAAAyxBAAAAAAFiGAAIAAADAMgQQAAAAAJYhgAAAAACwDAEEAAAAgGUIIAAAAAAsQwABAAAAYBkCCAAAAADLEEAAAAAAWIYAYpItW7bouuuuU1ZWltLT03XhhRdq0aJFqq6utrs0AAAAwDYpdhfgRVu3blV%2Bfr4GDBig%2B%2B%2B/X23bttUrr7yiadOmqbS0VPPnz7e7RAAAAMAWjICY4Mknn5TP59Mbb7yhadOmqaioSH6/X9/97ne1dOlSu8tDlIqLi%2B0uAc3g/DgX58a5ODfOxvmBVxFATHD8%2BHG1adNGHTt2DDneo0cPpaWl2VQVYsX/ETgb58e5ODfOxblxNs4PvIoAYoLLLrtMx44d009%2B8hN9/PHH2rdvn5588km9%2BOKLeuCBB%2BwuDwAAALANc0BMUFRUpO3bt%2Bupp57SH/7wB0lSSkqKFi9erJ/85Cc2VwcAAADYhwDSAsMwdOrUqbAem5qaKklKSkpSbm6urr32Wt1yyy1KTU1VcXGxpkyZoh49emj06NFmlgwAAAA4FgGkBRs2bNDll1/e4uN8Pp927NihAQMGaM6cOVq0aJFKSkrUtm1bSdLNN9%2BsK664Qj/72c903XXXKSmpYfdbZWWlJGnHjh3x/SUQF0ePHtXWrVvtLgNN4Pw4F%2BfGuTg3zsb5caaa67Sa6zZEzmcYhmF3EU4WCAS0Zs2asB570003KT09XX379tV3v/td/elPfwr5%2BYIFC3TvvfeqpKREOTk5DZ6/cuVK3XbbbXGpGwAAAOZZsWKFbr31VrvLcCVGQFrQvXt3TZw4MaLnBAIBnTlzpsHxqqoqSdLp06cbfd4111yjFStWKDs7m9WyAAAAHKiyslJ79uzRNddcY3cprsUIiAmGDBmi8vJy7dy5U507d5YkVVdXa8SIEdq1a5cOHTqk5ORkm6sEAAAArMcIiAnuv/9%2B/ehHP9KIESP0k5/8RGlpafrzn/%2Bs999/X7NnzyZ8AAAAIGExAmKSf/zjH3r88ce1fft2HTt2TAMHDtSUKVN0xx132F0aAAAAYBsCCAAAAADLsBM6AAAAAMsQQFxg7dq1uvLKK9WpUyd16NBBF110kZ5//nm7y0IdRVw0qjwAAAn2SURBVEVFSkpKYpNJB3j11Vc1efJkDRw4UO3atVNubq6Kior02Wef2V1aQjl16pTuu%2B8%2B9erVS23bttXIkSO1du1au8tKeJs3b9aUKVM0ePBgtW/fXn379tX48eNVUlJid2loxOzZs5WUlKQhQ4bYXQrO2rp1q0aPHq0uXbqoXbt2uuCCC7R48WK7y3IdWrAcbsmSJbrjjjt09dVXa/To0UpOTtYnn3yiXr166Z577rG7PCj4f%2BiXXHKJWrVqpSuvvFJ/%2B9vf7C4poQ0fPlxHjhzRuHHj1L9/f5WWlmrRokVq166dPvjgA2VmZtpdYkIoLCyU3%2B/X9OnT1a9fPy1dulSbNm3S%2BvXrdckll9hdXsIaN26c3nrrLY0bN05DhgzRZ599pkWLFunEiRN69913dd5559ldIs4qKyvTwIEDlZSUpOzsbH344Yd2l5Tw/v73v2v06NHKy8vT%2BPHj1b59e%2B3evVvV1dWaM2eO3eW5CgHEwfbu3avzzjtPd955p%2BbNm2d3OWhCfn6%2BzjvvPK1du1YXXHABAcRmGzduVEFBQcixN954Q6NGjdKMGTM0a9YsmypLHJs2bdLIkSP129/%2BVtOnT5cknTx5UoMHD1b37t21ceNGmytMXO%2B8844uuugipaScWwRz165duuCCCzRu3DgtX77cxupQ14QJE3To0CGdPn1ahw4dIoDY7Pjx4xowYIAKCgroQokDWrAc7Pe//72qq6s1c%2BZMSdKXX35pc0Wob/ny5dq%2Bfbtmz55tdyk4q374kKRLL71UGRkZ2rFjhw0VJZ5Vq1YpJSVFRUVFtcdSU1M1efJkvf322yorK7OxusQ2cuTIkPAhSf369dP555/Pfz8cZMOGDfL7/VqwYIHdpeCslStXqqKiovb/77/66ivxHX70CCAOtm7dOg0aNEgvv/yy%2BvTpo/T0dHXp0kUPP/wwH3oHOHHihO6//349%2BOCDtPU43JdffqkTJ06oa9eudpeSED744AMNGDBA7du3Dzk%2BYsSI2p/DWQKBAP/9cIjq6mrdfffdKioq0vnnn293OThr3bp16tChgz799FMNGjRI7du3V4cOHfTTn/5UJ0%2BetLs812EjQgcrKSlRcnKyJk2apPvuu09DhgyR3%2B/XY489pjNnzvCtu81mzpyptm3b6uc//7ndpaAF8%2BfPV1VVlSZMmGB3KQmhvLxcWVlZDY5nZWXJMAwdOHDAhqrQlBUrVqisrEyPPfaY3aVAwe6Hffv26dVXX7W7FNRRUlKiqqoq3XDDDSoqKtKcOXO0fv16LVy4UEePHtXKlSvtLtFVCCAWMQxDp06dCuuxqampkoLfsBuGoblz5%2BoXv/iFJOmmm27SoUOH9MQTT%2BiBBx5Qu3btTKs5UURzbnbu3KmFCxfqueeeU6tWrcwsL6FFc27q27Bhg2bNmqXx48dr1KhR8SwPTaisrGz0fLRp06b253CGjz/%2BWFOmTFF%2Bfr4mTpxodzkJ7/Dhw3rkkUf08MMPKyMjw%2B5yUMeJEydUWVmpu%2B66S/Pnz5ck3XjjjTp58qSefvppzZo1S7m5uTZX6R60YFlkw4YNSktLa/Ff27ZttXPnTklSWlqaJDX41rawsFCVlZV6//33Lf89vCiaczNt2jQVFBT8//buJiSqLgDj%2BHOXQQmTmOlGZyB0YSq6FNQBU8FIJxBBl9rO1KU4ulJcCaLLXCjoRkT8gKDAj0GKWoTUJgyGYNJRWqQg4lfatPB1yFcLFTvH973/3/IeF49c7sx57j1zj6qqqiyn/3%2B7zLn51dLSkh4/fqzs7GwNDAxY%2BA/c6caNG2cuSdjd3Y2Pw76vX7%2BqoqJCHo9HY2NjchzHdiTXCwaDSkxMVGNjo%2B0o%2BJffzclqa2sVi8X05s0bG7H%2Bs3gCYkhmZqaGhobO9bfHSxdSU1MVDoeVnJx8YvzOnTuKxWLa2Ni46piudNFzMzc3p5cvX2piYkKRSETS0Z36g4MD7ezsKBKJ6Pbt27p169ZfTO0Ol7luji0vL6u0tFQej0fPnz/naaFBKSkpZy6zWltbk3T02Qa7Njc3VV5ers3NTb169Up37961Hcn1wuGwBgYG1NfXF39RQywW0%2B7urr5//65IJKKEhAR5PB7LSd0pNTVVHz9%2BPHNOJok52QVRQAxJTk6%2B8OPt/Px8hcNhRaNRpaenx49Ho1E5jqOkpKQrTulOFz03y8vLchxHgUDgxHHHcRSNRuXz%2BdTb26umpqarjuo6l7lupKNlDKWlpTo4OFAoFDr1hYG/Kzc3V6FQSFtbWyd%2BiP727Vs5jqPc3FyL6bC3t6eHDx8qHA5rdnZWGRkZtiNBR9/tsVhMTU1Nevr06alxn8%2Bn5uZmXstvSX5%2BvmZmZhSNRnXv3r348eObLczJLoZ9QK6xqakpBQIBBYNBdXZ2Sjq6G1JYWKilpSWtrq7y%2BwMLVlZWtLi4eOr4kydPlJ6ervb2dmVlZcnr9VpIh%2B3tbfn9fn369EmhUIjJrgXH%2B4D09PTEN0zd399XVlaWkpKS9Pr1a8sJ3evHjx8KBAJ68eKFpqenVVZWZjsS/vHt27czr41gMKitrS319/fL5/PxZixL3r9/r7y8PNXV1Wl4eDh%2BvLa2VuPj44pEIjxJvAAKyDX34MEDzc/Pq6GhQTk5OZqYmNDs7KyePXum%2Bvp62/HwC6/Xy0aE10BVVZWmp6dVX1%2Bv4uLiE2M3b95UZWWlnWAuU1NTo8nJSbW0tMR3Qn/37p3m5uZUUFBgO55rtbS0qL%2B/X48ePVJ1dfWp8bq6Ogup8Cd%2Bv5%2BNCK%2BJhoYGDQ4Oqrq6WkVFRZqfn9f4%2BLja2triN4pxPhSQa257e1vt7e0aHR3V%2Bvq6MjIy1NrayutEryGfz6f79%2B9ramrKdhRX83q9%2BvLly5ljaWlp%2Bvz5s%2BFE7rS/v6%2BOjg6NjIxoY2ND2dnZ6urqUklJie1orub3%2B7WwsPDb8cPDQ4NpcB5%2Bv1/r6%2Bv68OGD7Siud3h4qO7ubg0ODmp1dVVpaWlqbGw8c8kc/owCAgAAAMAYXsMLAAAAwBgKCAAAAABjKCAAAAAAjKGAAAAAADCGAgIAAADAGAoIAAAAAGMoIAAAAACMoYAAAAAAMIYCAgAAAMAYCggAAAAAYyggAAAAAIyhgAAAAAAwhgICAAAAwBgKCAAAAABjKCAAAAAAjKGAAAAAADCGAgIAAADAGAoIAAAAAGMoIAAAAACMoYAAAAAAMIYCAgAAAMAYCggAAAAAYyggAAAAAIyhgAAAAAAwhgICAAAAwBgKCAAAAABjKCAAAAAAjKGAAAAAADCGAgIAAADAGAoIAAAAAGMoIAAAAACMoYAAAAAAMIYCAgAAAMAYCggAAAAAYyggAAAAAIyhgAAAAAAwhgICAAAAwBgKCAAAAABjKCAAAAAAjPkJ9MKFosIZL/UAAAAASUVORK5CYII%3D'/>\nTesting Error = 0.116666666667\n"}},{"config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/markdown","editorHide":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1459698663092_1606282850","id":"20160403-115103_1036425366","dateCreated":"Apr 3, 2016 11:51:03 AM","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:231","dateUpdated":"Apr 3, 2016 12:04:48 PM","dateFinished":"Apr 3, 2016 12:04:47 PM","dateStarted":"Apr 3, 2016 12:04:47 PM","result":{"code":"SUCCESS","type":"HTML","msg":"<hr />\n<h3>Question 11.4</h3>\n<p><i>Use the non-linearly separable training and testing datasets from HW11.3 in this problem.</i></p><br>\n<p><i>Using MLLib  train up a soft SVM model with the training dataset and evaluate with the testing set. What is a good number of iterations for training the SVM model? Justify with plots and words.</i> </p><br>\n<p><i>Derive and Implement in Spark a weighted soft linear svm classification learning algorithm. Evaluate your homegrown weighted soft linear svm classification learning algorithm on the weighted training dataset and test dataset from HW11.3. Report misclassification error (1 - Accuracy) and how many iterations does it took to converge?  How many support vectors do you end up?</i></p><br>\n<p><i>Does Spark MLLib have a weighted soft SVM learner. If so use it and report your findings on the weighted training set and test set. </i></p><br>\n<h4>Solution:</h4>\n"},"text":"%md \n\n-----\n\n### Question 11.4 ###\n\n<p><i>Use the non-linearly separable training and testing datasets from HW11.3 in this problem.</i></p><br>\n\n<p><i>Using MLLib  train up a soft SVM model with the training dataset and evaluate with the testing set. What is a good number of iterations for training the SVM model? Justify with plots and words.</i> </p><br>\n\n<p><i>Derive and Implement in Spark a weighted soft linear svm classification learning algorithm. Evaluate your homegrown weighted soft linear svm classification learning algorithm on the weighted training dataset and test dataset from HW11.3. Report misclassification error (1 - Accuracy) and how many iterations does it took to converge?  How many support vectors do you end up?</i></p><br>\n\n<p><i>Does Spark MLLib have a weighted soft SVM learner. If so use it and report your findings on the weighted training set and test set. </i></p><br>\n\n#### Solution: ####"},{"config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1459698770649_521091737","id":"20160403-115250_863383697","dateCreated":"Apr 3, 2016 11:52:50 AM","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:265","dateUpdated":"Apr 3, 2016 1:25:05 PM","dateFinished":"Apr 3, 2016 1:25:05 PM","dateStarted":"Apr 3, 2016 1:25:05 PM","result":{"code":"SUCCESS","type":"ANGULAR","msg":"<!DOCTYPE html>\n<html>\n<head>\n<title>MathJax Test Page</title>\n<script type=\"text/javascript\"\n  src=\"https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML\"></script>\n</head>\n<body>\n\n<p>When `a != 0`, there are two solutions to `ax^2 + bx + c = 0` and\nthey are</p>\n<p style=\"text-align:center\">\n  `x = (-b +- sqrt(b^2-4ac))/(2a) .`\n</p>\n\n</body>\n</html>"},"text":"%angular\n<!DOCTYPE html>\n<html>\n<head>\n<title>MathJax Test Page</title>\n<script type=\"text/javascript\"\n  src=\"https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML\"></script>\n</head>\n<body>\n\n<p>When `a != 0`, there are two solutions to `ax^2 + bx + c = 0` and\nthey are</p>\n<p style=\"text-align:center\">\n  `x = (-b +- sqrt(b^2-4ac))/(2a) .`\n</p>\n\n</body>\n</html>"},{"config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/sh"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1459704255691_2063287620","id":"20160403-132415_1048035998","dateCreated":"Apr 3, 2016 1:24:15 PM","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:356","dateUpdated":"Apr 3, 2016 3:16:24 PM","dateFinished":"Apr 3, 2016 3:16:26 PM","dateStarted":"Apr 3, 2016 3:16:24 PM","result":{"code":"SUCCESS","type":"TEXT","msg":"/Users/john/zeppelin-0.5.6-incubating\n"},"text":"%sh \npwd"},{"config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1459710984842_853057975","id":"20160403-151624_457540016","dateCreated":"Apr 3, 2016 3:16:24 PM","status":"READY","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:560"}],"name":"Krunic-Homework11","id":"2BERZEEZ8","angularObjects":{"2BGKJQDDV":[],"2BHHUZJUC":[],"2BF5CG42C":[],"2BG81HVUC":[],"2BGZSEG83":[],"2BFHD9GFA":[],"2BJ9AWN52":[],"2BF5N9B7F":[],"2BGGBAXAS":[],"2BEZBSCMA":[],"2BH2B4FK2":[],"2BG8X9JYD":[],"2BGX6YZQG":[],"2BJ6AG5XQ":[]},"config":{"looknfeel":"default"},"info":{}}